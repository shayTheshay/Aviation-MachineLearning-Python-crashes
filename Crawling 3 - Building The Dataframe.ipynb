{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ddc4d5a",
   "metadata": {},
   "source": [
    "<h1>Crawling Step 3 - Building The Dataframe</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7ca408",
   "metadata": {},
   "source": [
    "<h2>Preliminary Steps</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1de65b8",
   "metadata": {},
   "source": [
    "Let's begin with importing the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "430843ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup  \n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a451003",
   "metadata": {},
   "source": [
    "We need to declare multiple necessary general variables that will be used throughout this step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6385fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = \"https://aviation-safety.net\" # The main website's URL to whom various extensions will be concatenated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236e8a26",
   "metadata": {},
   "source": [
    "The files we created in the previous two steps will come in handy during this step<br>\n",
    "therefore, we need to load them and convert them to the structures they were extracted from beforehand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3542006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the accidents' URLs file, created in Crawling Step 1:\n",
    "with open(\"accidents_urls.txt\", \"r\") as lk_file:\n",
    "    list_of_urls = [line.strip() for line in lk_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fd301cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the aircrafts to engines file, created in Crawling Step 2:\n",
    "with open('aircrafts_to_engines.txt') as ae_file:\n",
    "    ae_dict = json.load(ae_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ff520b",
   "metadata": {},
   "source": [
    "Let's test if the files were loaded properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1772cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/database/record.php?id=19190802-0\n",
      "/database/record.php?id=19190811-0\n",
      "/database/record.php?id=19200223-0\n",
      "/database/record.php?id=19200225-0\n",
      "/database/record.php?id=19200630-0\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "for u in range(0,5):\n",
    "    print(list_of_urls[u])\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db517d11",
   "metadata": {},
   "source": [
    "Let's see how many URLs we need to access, to have better assessment of our scraping process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "670a2329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22252"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfe191bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Aero Modifications AMI DC-3-65TP', 'turboprop (2)')\n",
      "('Aero Spacelines Mini Guppy Turbine', 'turboprop (4)')\n",
      "('Aeromarine 75', 'piston (2)')\n",
      "('Aérospatiale SN.601 Corvette', 'jet (2)')\n",
      "('Airbus A220 / Bombardier Cseries', 'jet (2)')\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "for u in range(0,5):\n",
    "    print(list(ae_dict.items())[u])\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7dde79",
   "metadata": {},
   "source": [
    "<h2>The Process</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23550f25",
   "metadata": {},
   "source": [
    "<h3>Scraping Accident Data</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5557f638",
   "metadata": {},
   "source": [
    "We are ready to begin scraping the necessary data from each and every accident page!<br>\n",
    "Let's begin with declaring lists that will represent the columns in our dataframe to-be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8547009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns will be elaborately explained in the Data Handling step.\n",
    "weekday = []\n",
    "day = []\n",
    "month =[]\n",
    "year = []\n",
    "time_c = []\n",
    "aircraft_type = []\n",
    "num_of_engines = []\n",
    "engine_type = []\n",
    "engine_model = []\n",
    "years_active = []\n",
    "airframe_hrs = []\n",
    "cycles = []\n",
    "operator = []\n",
    "occupants = []\n",
    "accident_loc =[]\n",
    "above_ocean = []\n",
    "flight_phase = []\n",
    "damage = []\n",
    "fate = []\n",
    "accident_latitude = []\n",
    "accident_longtitude = []\n",
    "fatalities = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997083be",
   "metadata": {},
   "source": [
    "In the following section, the code will loop through the URLs that were collected in Step 1.<br>\n",
    "Since all these pages have the same template, we know that all the necessary data will appear in two fields:<br>\n",
    "<ul><b>A 'table' HTML tag</b> - that contains string and numerical data about the accident, in two seperate columns. These are appropriate to be organized in a dictionary for better data processing.</ul>\n",
    "<ul><b>An external web object</b> - that redirects to a world map website that shows the accident's location. We will scrape the coordinates from the map script and will append them directly to the appropriate lists</ul><br><br>\n",
    "After scraping is complete, we will append every given data to its appropriate list. If there's a list whose appropriate data is missing from the page, or whose relevant data is corrupted, a NaN object will be appended to the list instead.<br><br>\n",
    "<small>Note: Most of the commands to be performed in this section need to be inserted to a loop, which require us to implement them in a single Jupyter notebook code cell. It means that code-specific remarks must be included as comments within the code, and not as markdowns</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f6029ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're about to access the website a large amount of times, therefore pauses need to be introduced to avoid server blocking.\n",
    "\n",
    "sleep_counter = 0\n",
    "\n",
    "#-------------------\n",
    "\n",
    "for x in list_of_urls:\n",
    "    \n",
    "# For every fifth iteration we will introduce a pause (on one hand, to avoid being blocked. On the other hand, we don't want the process to take a VERY long time)\n",
    "# With 22,252 projected entries, it is estimated that the scraping will be a few hours long...\n",
    "\n",
    "    if(sleep_counter%10 == 0):\n",
    "        time.sleep(0.3)\n",
    "    sleep_counter = sleep_counter + 1\n",
    "    \n",
    "#Now it's time to send a request to every URL, and build a BeautifulSoup object from every response we receive.\n",
    "#The website is very wary of scraping attempts, therefore we mask our presence using the 'User-Agent': 'Mozilla/5.0' header.\n",
    "\n",
    "    accident_url = main_url + x #Declares the complete URL to scrape from\n",
    "    response_data = requests.get(accident_url, headers={'User-Agent': 'Mozilla/5.0'}) #Request and response\n",
    "    soup = BeautifulSoup(response_data.content, \"html.parser\") #Setting the BeautifulSoup object\n",
    "    \n",
    "#Now that we have the BeautifulSoup object, let's access the two fields mentioned above to scrape data from:\n",
    "\n",
    "#STEP 1.1 - The 'table' HTML tag:\n",
    "#_______________________________\n",
    "#The accident page has multiple 'table' tags, but we sampled few dozens and found out the desired table will always be the\n",
    "#the first one on the page. Therefore, we can use the '.find' attribute to isolate it to an object.\n",
    "#Then we will set up an empty dictionary with the key being the left column of the table, and the value being the right.\n",
    "#We will create an array of the table' rows using the '.find_all' attribute on the 'tr' tags in the table object.\n",
    "#Then we move on to scrape the data and append it to the dictionary:\n",
    "\n",
    "    try:\n",
    "        table = soup.find(\"table\")\n",
    "        tb_rows = table.find_all(\"tr\")\n",
    "        tb_length = len(tb_rows) #Calculates the number of rows in the table, for looping purposes\n",
    "        tb_dict = {}\n",
    "        for i in range(0, tb_length): #Loops from the first row to the last row in the rows list\n",
    "            tb_row = table.select('tr')[i] #Selects the row\n",
    "            tb_dict[tb_row.select('td')[0].text[:-1]] = tb_row.select('td')[1].text #Creates a dictionary record for each row\n",
    "    except: #If the page is corrupted, it won't include the table object, Therfore we will skip it to the next page\n",
    "        continue\n",
    "\n",
    "#The dictionary is ready for processing!\n",
    "#------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#STEP 1.2: The external map object:\n",
    "#________________________________\n",
    "#This one was a bit trickier. The data is not shown on the page as text, but rather as a visual representation of it in a map.\n",
    "#The map object is external - which means that unlike the table, its code is not loaded into our BeautifulSoup object.\n",
    "#Therefore, we need to access the object seperately and get its HTML code in another BeautifulSoup object.\n",
    "\n",
    "#The first step is to understand, and obviously locate the object and the external link the is used to represent it\n",
    "#within the accident page. Other information objects in th page are located in 'iframe' tags, including our map.\n",
    "#However, unlike the table, its location in the page is not fixed, and the map might even be missing.\n",
    "#We understood how the URL of the map object looks like, so we will find all the 'iframe' tags, and loop through them to\n",
    "#find the specific tag that includes the map URL template (or to return nothing if there is no map in the page):\n",
    "\n",
    "    num_of_infos = len(soup.find_all(\"iframe\")) #Calculates the number of info objects, for looping purposes\n",
    "    for n in range(0,num_of_infos):\n",
    "        try:\n",
    "            tmap = soup.select(\"iframe\")[n] #Selects the current info object\n",
    "            if (re.search('/statistics/geographical/kml_map_iframe.php' ,tmap['src'])): #Checks if it's external URL has the map object's URL template\n",
    "                map_url = main_url + tmap['src'] #If yes, declares a variable with the map object's full URL\n",
    "                map_script = requests.get(map_url, headers={'User-Agent': 'Mozilla/5.0'}).text #Request-response of the map object's HTML code\n",
    "                break #Loop is broken, as the map object was found. No need to keep looking further\n",
    "            else: #\n",
    "                map_script = None\n",
    "        except: #In a case there is not a single info object in the page, so an error won't abort our loop\n",
    "            map_script = None\n",
    "            break;\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#Now we have the following variables with scraped data in hand that we need to process in different approaches:\n",
    "#1) A dictionary of the accident data\n",
    "#2) A dictionary of aircrafts and engines data\n",
    "#3) The HTML code of the map script.\n",
    "\n",
    "#We can now start processing our data and append the processed values to the relevant column lists.\n",
    "#As mentioned above, if a certain page doesn't include the data (and that data doesn't appear in the dictionary/script as\n",
    "#a result), a NaN value will be appended to the matching list instead.\n",
    "\n",
    "#STEP 2.1: Processing of the dictionary object:\n",
    "#____________________________________________\n",
    "\n",
    "#Processing values from the accident's freshly created dictionary is pretty straightforward. We will either take the value\n",
    "#directly from the dictionary, or - in a case the needed value is enclaved in a string - will use text processing:\n",
    "\n",
    "#Weekday - Always indicated in the first word of the \"Date\" dictionary value\n",
    "    try:\n",
    "        weekday_i = re.split(\" \",tb_dict[\"Date\"])[0]\n",
    "        if ((weekday_i == 'xx') | (weekday_i == 'XX')): # If exact date is unknown\n",
    "            weekday.append(np.nan)\n",
    "        else:\n",
    "            weekday.append(weekday_i)\n",
    "    except:\n",
    "        weekday_i = np.nan\n",
    "        weekday.append(weekday_i)\n",
    "\n",
    "#Day - Mostly the second word of the \"Date\" dictionary value. Numerical - converted to float\n",
    "    try:\n",
    "        if ((weekday_i == 'xx') | (weekday_i == 'XX')): # If exact date is unknown\n",
    "            day_i = np.nan\n",
    "        else:\n",
    "            day_i = float(re.split(' ',tb_dict[\"Date\"])[1]) # If exact date is unknown\n",
    "    except:\n",
    "        day_i = np.nan\n",
    "    day.append(day_i)\n",
    "\n",
    "#Month - Mostly the third word of the \"Date\" dictionary value.\n",
    "    try:\n",
    "        if ((weekday_i == 'xx') | (weekday_i == 'XX')): # If exact date is unknown\n",
    "            month_i = np.nan\n",
    "        else:\n",
    "            month_i = re.split(\" \",tb_dict[\"Date\"])[2]\n",
    "    except:\n",
    "        month_i = np.nan\n",
    "    month.append(month_i)\n",
    "\n",
    "#Year - #Day - Mostly the fourth word of the \"Date\" dictionary value. Numerical - converted to float\n",
    "    try:\n",
    "        if ((weekday_i == 'xx') | (weekday_i == 'XX')): # If exact date is unknown\n",
    "            year_i = float(re.split(\" \",tb_dict[\"Date\"])[2]) #Year will appear in the third word\n",
    "        else:\n",
    "            year_i = float(re.split(\" \",tb_dict[\"Date\"])[3]) #Year will appear in the fourth word\n",
    "    except:\n",
    "        year_i = np.nan\n",
    "    year.append(year_i)\n",
    "\n",
    "#Time - Appears in HH:MM format as the value of \"Time\" in the dictionary. We wanted to represent the time as a float number\n",
    "#for it to be a sequential variable. The hour is taken as the number, and the minutes are taken as the relative part\n",
    "#out of 60 and added to the number.\n",
    "    try:\n",
    "        time_i = float(re.search(\"\\d\\d\", re.split(\":\",tb_dict[\"Time\"])[0]).group(0))+float((re.split(\":\",tb_dict[\"Time\"])[1]))/60\n",
    "    except:\n",
    "        time_i = np.nan\n",
    "    time_c.append(time_i)\n",
    "\n",
    "#Airframe Hours - directly taken from \"Total airframe hrs\" dictionary value.Numerical - converted to float\n",
    "    try:\n",
    "        airframe_hrs_i = float(tb_dict[\"Total airframe hrs\"])\n",
    "    except:\n",
    "        airframe_hrs_i = np.nan\n",
    "    airframe_hrs.append(airframe_hrs_i)\n",
    "\n",
    "#Cycles - directly taken from the \"Cycles\" dictionary value. Numerical - converted to float\n",
    "    try:\n",
    "        cycles_i = float(tb_dict[\"Cycles\"])\n",
    "    except:\n",
    "        cycles_i = np.nan\n",
    "    cycles.append(cycles_i)\n",
    "\n",
    "#Operator - directly taken from the \"Operator\" dictionary value.\n",
    "    try:\n",
    "        operator_i = tb_dict[\"Operator\"]\n",
    "    except:\n",
    "        operator_i = np.nan\n",
    "    operator.append(operator_i)\n",
    "\n",
    "#Flight Phase - The sub-string that is located between the parentheses in the \"Phase\" dictionary value.\n",
    "    try:\n",
    "        flight_phase_i = re.split('[()]',tb_dict[\"Phase\"])[1]\n",
    "    except:\n",
    "        flight_phase_i = np.nan\n",
    "    flight_phase.append(flight_phase_i)\n",
    "\n",
    "#Years Active - Processes the \"First flight\" dictionary value, as its template might vary depending on  the aircraft's age\n",
    "#and the amount of available information given in this field.\n",
    "    try:\n",
    "        try:\n",
    "            re.search('\\d\\d\\d\\d-', tb_dict['First flight']).span() #Checks if more than first flight's year is provided. If yes, continues to the conditional statement\n",
    "            if(re.split(\" \", tb_dict['First flight'])[4] == 'months)'): #Checks if aircraft is less than 1 year old, if it is - takes the months relatively to 12\n",
    "                years_active_i = float(re.split(\" \", tb_dict['First flight'])[3][1:])/12\n",
    "            elif(re.split(\" \", tb_dict['First flight'])[4] == 'years)'): #Checks if the aircraft is exactly # years old (no months), if it is - takes the year as an int\n",
    "                years_active_i = float(re.split(\" \", tb_dict['First flight'])[3][1:])\n",
    "            else: #Gets the year and months since aircraft's first flight and converts them to a float number\n",
    "                years_active_i = float(re.findall(\"\\d+\", tb_dict['First flight'])[3])+float(re.findall(\"\\d+\", tb_dict['First flight'])[4])/12\n",
    "        except:\n",
    "            years_active_i = year_i - float(tb_dict[\"First flight\"][1:5]) #If error occurs in the nested 'try' (may occur if it checks out of range), it means that not enough data is available, therefore only a year is given and caculates the time elapsed in natural number of years\n",
    "    except:\n",
    "        years_active_i = np.nan\n",
    "    years_active.append(years_active_i)\n",
    "\n",
    "#Occupants - The second number that appears in the \"Total\" dictionary value. Numerical - converted to float\n",
    "    try:\n",
    "        occupants_i = float(re.findall('\\d+',tb_dict[\"Total\"])[1])\n",
    "    except:\n",
    "        occupants_i = np.nan\n",
    "    occupants.append(occupants_i)\n",
    "\n",
    "#Accident Location - Appears inside the parentheses and after the word '\\xa0' in the \"Location\" dictionary value.\n",
    "    try:\n",
    "        accident_loc_i = re.split('[)]',re.split('\\xa0 ', tb_dict['Location'])[1])[0]\n",
    "    except:\n",
    "        accident_loc_i = np.nan\n",
    "    accident_loc.append(accident_loc_i)\n",
    "\n",
    "#Above Ocean - Looks for appropriate word in the processed Accident Location variable.\n",
    "    try:\n",
    "        if (re.search(\"Ocean|Sea\", accident_loc_i)):\n",
    "            above_ocean_i = 1\n",
    "        else:\n",
    "            above_ocean_i = 0\n",
    "    except:\n",
    "        above_ocean_i = np.nan\n",
    "    above_ocean.append(above_ocean_i)\n",
    "\n",
    "#Damage - The sub-string before parentheses in \"Aircraft damage\" dictionary value (if there are any, if not - takes the entire value)\n",
    "    try:\n",
    "        damage_i = re.split('[(]',tb_dict['Aircraft damage'])[0][1:]\n",
    "    except:\n",
    "        damage_i = np.nan\n",
    "    damage.append(damage_i)\n",
    "\n",
    "#Fate - The sub-string before parentheses in \"Aircraft fate\" dictionary value (if there are any, if not - takes the entire value)\n",
    "    try:\n",
    "        fate_i = re.split('[(]',tb_dict['Aircraft fate'])[0][1:]\n",
    "    except:\n",
    "        fate_i = np.nan\n",
    "    fate.append(fate_i)\n",
    "\n",
    "#Fatalities - The first number that appears in the \"Total\" dictionary value. Numerical - converted to float\n",
    "    try:\n",
    "        fatalities_i = float(re.findall('\\d+',tb_dict[\"Total\"])[0])\n",
    "    except:\n",
    "        fatalities_i = np.nan\n",
    "    fatalities.append(fatalities_i)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#STEP 2.2: Processing of aircraft and engines information\n",
    "#________________________________________________________\n",
    "\n",
    "#In Crawling Step 2 we created a special dictionary that matches the engine type and amount to the aircraft's model.\n",
    "#In the accident page, the model is mentioned with a very specific name, that points on a sub-model, that if we decided to\n",
    "#scrape directly, would bloat the number of unique values for the Aircraft Model column.\n",
    "#The accident page also contains a hyperlink to the model's details page, where the aricraft model is mentioned with a more\n",
    "#general name, that we want to use as the value for the accident's involved aircraft model.\n",
    "#Since this name doesn't appear on our accident page, we need to access this hyperlink and scrape the name from the other page.\n",
    "#Therefore, we need yet another BeautifulSoup object to be able to scrape from a different page.\n",
    "#We will use the same method on the Engine Model column, as it follows the same pattern (sub-models mentioned in the accident\n",
    "#page, but more general name in the engine information page)\n",
    "\n",
    "#Some accident pages also lack the amount and type of engines, but these are pre-known as long as the aircraft model is known.\n",
    "#That's where the dictionary we created in Crawling Step 2, comes into play. We will match the general name of the aircraft model\n",
    "#to the type and amount of engines it is set to have. So even if the accident page lacks information about engines, we will be\n",
    "#able to gather it from elsewhere:\n",
    "\n",
    "    acen_links = table.find_all(\"a\") #Finds all hyperlinks in the accident's page\n",
    "\n",
    "# Aircaft Model - Scrapes the aircraft model info page's title, omits excess characters (They appear the same in every page)\n",
    "    try:\n",
    "        ac_link = None\n",
    "        for lnk in acen_links: #Looks for a hyperlink with the template of aircraft model info page's URL\n",
    "            if (re.search('database/types', str(lnk))):\n",
    "                ac_link = lnk['href'] # If found, declares a variable with the URL\n",
    "            \n",
    "        if ac_link != None: #If a matching hyperlink was found:\n",
    "            ac_url = main_url + ac_link #Declares a variable with the aircraft model's info page's full URL\n",
    "            ac_response = requests.get(ac_url, headers={'User-Agent': 'Mozilla/5.0'}) #Request-response of the info page's HTML code\n",
    "            ac_soup = BeautifulSoup(ac_response.content, \"html.parser\") #Creates BeautifulSoup object for it\n",
    "            \n",
    "            aircraft_type_i = ac_soup.find('div', attrs={\"class\":\"pagetitle\"}).text[1:-7]\n",
    "        else:\n",
    "            aircraft_type_i = np.nan\n",
    "    except:\n",
    "        aircraft_type_i = np.nan\n",
    "    aircraft_type.append(aircraft_type_i)\n",
    "\n",
    "#Engine Type - The first word in the dictionary value from Crawling Step 2 of the aircraft model we just scraped (the key)\n",
    "    try:\n",
    "        engine_i = re.split(' ', ae_dict[aircraft_type_i])[0]\n",
    "    except:\n",
    "        engine_i = np.nan\n",
    "    engine_type.append(engine_i)\n",
    "        \n",
    "\n",
    "#Num of Engines - Omits the parentheses of the second word from Crawling Step 2 of the aircraft model we just scraped (the key)\n",
    "#Numerical - converted to float\n",
    "    try:\n",
    "        num_of_engines_i = float(re.split(' ', ae_dict[aircraft_type_i])[1][1:-1])\n",
    "    except:\n",
    "        num_of_engines_i = np.nan\n",
    "    num_of_engines.append(num_of_engines_i)\n",
    "\n",
    "#Engine Model - Scrapes the engine model info page's title, omits excess characters (They appear the same in every page)   \n",
    "    try:\n",
    "        en_link = None\n",
    "        for lnk in acen_links: #Looks for a hyperlink with the template of engine model info page's URL\n",
    "            if (re.search('database/engine', str(lnk))):\n",
    "                en_link = lnk['href'] # If found, declares a variable with the URL\n",
    "        \n",
    "        if en_link != None: #If a matching hyperlink was found:\n",
    "            en_url = main_url + en_link #Declares a variable with the aircraft model's info page's full URL\n",
    "            en_response = requests.get(en_url, headers={'User-Agent': 'Mozilla/5.0'}) #Request-response of the info page's HTML code\n",
    "            en_soup = BeautifulSoup(en_response.content, \"html.parser\") #Creates BeautifulSoup object for it\n",
    "        \n",
    "            engine_model_i = en_soup.find('div', attrs={\"class\":\"pagetitle\"}).text[1:-7]\n",
    "        else:\n",
    "            engine_model_i = np.nan\n",
    "    except:\n",
    "        engine_model_i = np.nan\n",
    "    engine_model.append(engine_model_i)\n",
    "    \n",
    "#------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#STEP 2.3 - Processing the map script\n",
    "#____________________________________\n",
    "\n",
    "#The map script we got is treated like a string. The accident's coordinates appear inside that string, along with other\n",
    "#coordinates we decided not to include in our dataframe: Departure airport and destination airport.\n",
    "#Sampling some map scripts, we realized that the accident's coordintes will always appear after the departure and destination\n",
    "#airports in the script. \n",
    "\n",
    "#They also follow three other patterns:\n",
    "#1)Every coordinates field appears right after the term \"L.marker\".  The values we need are located in the third coordinates\n",
    "#field, so we need to process the sub-string that comes after the third \"L.marker\" appearance,\n",
    "#which means - the fourh sub-string overall.\n",
    "#2)A pair of coordinates always appear inside square bracket '[ ]'\n",
    "#3)The individual values in the pair of coordinates (latitude and longtitude) are seperated by a comma ','\n",
    "#The first value refers to the latitude, and the scond to the longtitude\n",
    "\n",
    "\n",
    "#We now follow these patterns from 3) to 1) and use text processing to isolate the values we need\n",
    "\n",
    "#Accident's Latitude - The first value in the third square brackets after the third \"L.marker\" appearance. Numerical - converted to float\n",
    "    try:\n",
    "        accident_latitude_i = float(re.split('[, ]', re.split('[\\[\\]]', re.split(\"L.marker\", map_script)[3])[1])[0])\n",
    "    except:\n",
    "        accident_latitude_i = np.nan\n",
    "    accident_latitude.append(accident_latitude_i)\n",
    "\n",
    "#Accident's Latitude - The second value in the third square brackets after the third \"L.marker\" appearance. Numerical - converted to float\n",
    "    try:\n",
    "        accident_longtitude_i = float(re.split('[, ]', re.split('[\\[\\]]', re.split(\"L.marker\", map_script)[3])[1])[2])\n",
    "    except:\n",
    "        accident_longtitude_i = np.nan\n",
    "    accident_longtitude.append(accident_longtitude_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dd5ad6",
   "metadata": {},
   "source": [
    "We're finally done! We have all the data we need appended to the column lists!<br>\n",
    "It means we're ready to build the dataframe with all the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bd8513e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>time</th>\n",
       "      <th>aircraft_type</th>\n",
       "      <th>num_of_engines</th>\n",
       "      <th>engine_type</th>\n",
       "      <th>engine_model</th>\n",
       "      <th>years_active</th>\n",
       "      <th>...</th>\n",
       "      <th>operator</th>\n",
       "      <th>occupants</th>\n",
       "      <th>accident_loc</th>\n",
       "      <th>above_ocean</th>\n",
       "      <th>flight_phase</th>\n",
       "      <th>damage</th>\n",
       "      <th>fate</th>\n",
       "      <th>accident_latitude</th>\n",
       "      <th>accident_longtitude</th>\n",
       "      <th>fatalities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>2.0</td>\n",
       "      <td>August</td>\n",
       "      <td>1919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Caproni Ca.48</td>\n",
       "      <td>3.0</td>\n",
       "      <td>piston</td>\n",
       "      <td>Liberty L-12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>Caproni</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Italy</td>\n",
       "      <td>0</td>\n",
       "      <td>ENR</td>\n",
       "      <td>Destroyed</td>\n",
       "      <td>Written off</td>\n",
       "      <td>45.396389</td>\n",
       "      <td>10.888056</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Monday</td>\n",
       "      <td>11.0</td>\n",
       "      <td>August</td>\n",
       "      <td>1919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Felixstowe Fury</td>\n",
       "      <td>5.0</td>\n",
       "      <td>piston</td>\n",
       "      <td>Rolls-Royce Eagle VIII</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>Royal Air Force - RAF</td>\n",
       "      <td>7.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0</td>\n",
       "      <td>ICL</td>\n",
       "      <td>Damaged beyond repair</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.941370</td>\n",
       "      <td>1.306789</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Monday</td>\n",
       "      <td>23.0</td>\n",
       "      <td>February</td>\n",
       "      <td>1920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Handley Page Type O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>piston</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>Handley Page Transport</td>\n",
       "      <td>10.0</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>0</td>\n",
       "      <td>ENR</td>\n",
       "      <td>Damaged beyond repair</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>25.0</td>\n",
       "      <td>February</td>\n",
       "      <td>1920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Handley Page Type O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>piston</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Handley Page Transport</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>0</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Damaged beyond repair</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>30.0</td>\n",
       "      <td>June</td>\n",
       "      <td>1920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Handley Page Type O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>piston</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>Handley Page Transport</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>0</td>\n",
       "      <td>ENR</td>\n",
       "      <td>Damaged beyond repair</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22215</th>\n",
       "      <td>Monday</td>\n",
       "      <td>27.0</td>\n",
       "      <td>December</td>\n",
       "      <td>2021</td>\n",
       "      <td>19.233333</td>\n",
       "      <td>Learjet 35 / 36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>jet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.00</td>\n",
       "      <td>...</td>\n",
       "      <td>Aeromedevac Air Ambulance</td>\n",
       "      <td>4.0</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>0</td>\n",
       "      <td>APR</td>\n",
       "      <td>Destroyed</td>\n",
       "      <td>Written off</td>\n",
       "      <td>32.821172</td>\n",
       "      <td>-116.939520</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22216</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>28.0</td>\n",
       "      <td>December</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cessna 208 Caravan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>turboprop</td>\n",
       "      <td>Pratt &amp; Whitney Canada PT6</td>\n",
       "      <td>25.00</td>\n",
       "      <td>...</td>\n",
       "      <td>Halsted Aviation Corporation (HAC)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mozambique</td>\n",
       "      <td>0</td>\n",
       "      <td>LDG</td>\n",
       "      <td>Damaged beyond repair</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22217</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>28.0</td>\n",
       "      <td>December</td>\n",
       "      <td>2021</td>\n",
       "      <td>11.883333</td>\n",
       "      <td>Beechcraft 100 King Air</td>\n",
       "      <td>2.0</td>\n",
       "      <td>turboprop</td>\n",
       "      <td>Pratt &amp; Whitney Canada PT6</td>\n",
       "      <td>47.00</td>\n",
       "      <td>...</td>\n",
       "      <td>Sky-Bound Aviation LLC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>0</td>\n",
       "      <td>LDG</td>\n",
       "      <td>Substantial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22218</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>30.0</td>\n",
       "      <td>December</td>\n",
       "      <td>2021</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>Beechcraft Super King Air</td>\n",
       "      <td>2.0</td>\n",
       "      <td>turboprop</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.00</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Guatemala</td>\n",
       "      <td>0</td>\n",
       "      <td>LDG</td>\n",
       "      <td>Damaged beyond repair</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22219</th>\n",
       "      <td>Friday</td>\n",
       "      <td>31.0</td>\n",
       "      <td>December</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Britten-Norman BN-2 Islander</td>\n",
       "      <td>2.0</td>\n",
       "      <td>piston</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Royal Moroccan Gendarmerie</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>0</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22220 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         weekday   day     month  year       time  \\\n",
       "0       Saturday   2.0    August  1919        NaN   \n",
       "1         Monday  11.0    August  1919        NaN   \n",
       "2         Monday  23.0  February  1920        NaN   \n",
       "3      Wednesday  25.0  February  1920        NaN   \n",
       "4      Wednesday  30.0      June  1920        NaN   \n",
       "...          ...   ...       ...   ...        ...   \n",
       "22215     Monday  27.0  December  2021  19.233333   \n",
       "22216    Tuesday  28.0  December  2021        NaN   \n",
       "22217    Tuesday  28.0  December  2021  11.883333   \n",
       "22218   Thursday  30.0  December  2021  17.000000   \n",
       "22219     Friday  31.0  December  2021        NaN   \n",
       "\n",
       "                      aircraft_type  num_of_engines engine_type  \\\n",
       "0                     Caproni Ca.48             3.0      piston   \n",
       "1                   Felixstowe Fury             5.0      piston   \n",
       "2               Handley Page Type O             2.0      piston   \n",
       "3               Handley Page Type O             2.0      piston   \n",
       "4               Handley Page Type O             2.0      piston   \n",
       "...                             ...             ...         ...   \n",
       "22215               Learjet 35 / 36             2.0         jet   \n",
       "22216            Cessna 208 Caravan             1.0   turboprop   \n",
       "22217       Beechcraft 100 King Air             2.0   turboprop   \n",
       "22218     Beechcraft Super King Air             2.0   turboprop   \n",
       "22219  Britten-Norman BN-2 Islander             2.0      piston   \n",
       "\n",
       "                     engine_model  years_active  ...  \\\n",
       "0                    Liberty L-12          0.00  ...   \n",
       "1          Rolls-Royce Eagle VIII          0.75  ...   \n",
       "2                             NaN          1.00  ...   \n",
       "3                             NaN           NaN  ...   \n",
       "4                             NaN          1.00  ...   \n",
       "...                           ...           ...  ...   \n",
       "22215                         NaN         36.00  ...   \n",
       "22216  Pratt & Whitney Canada PT6         25.00  ...   \n",
       "22217  Pratt & Whitney Canada PT6         47.00  ...   \n",
       "22218                         NaN         34.00  ...   \n",
       "22219                         NaN           NaN  ...   \n",
       "\n",
       "                                 operator  occupants  \\\n",
       "0                                 Caproni       14.0   \n",
       "1                   Royal Air Force - RAF        7.0   \n",
       "2                  Handley Page Transport       10.0   \n",
       "3                  Handley Page Transport        4.0   \n",
       "4                  Handley Page Transport        2.0   \n",
       "...                                   ...        ...   \n",
       "22215           Aeromedevac Air Ambulance        4.0   \n",
       "22216  Halsted Aviation Corporation (HAC)        NaN   \n",
       "22217              Sky-Bound Aviation LLC        NaN   \n",
       "22218                             Unknown        3.0   \n",
       "22219          Royal Moroccan Gendarmerie        3.0   \n",
       "\n",
       "                   accident_loc  above_ocean flight_phase  \\\n",
       "0                         Italy            0          ENR   \n",
       "1                United Kingdom            0          ICL   \n",
       "2                  South Africa            0          ENR   \n",
       "3                         Sudan            0          UNK   \n",
       "4                        Sweden            0          ENR   \n",
       "...                         ...          ...          ...   \n",
       "22215  United States of America            0          APR   \n",
       "22216                Mozambique            0          LDG   \n",
       "22217  United States of America            0          LDG   \n",
       "22218                 Guatemala            0          LDG   \n",
       "22219                   Morocco            0          UNK   \n",
       "\n",
       "                      damage          fate accident_latitude  \\\n",
       "0                  Destroyed  Written off          45.396389   \n",
       "1      Damaged beyond repair           NaN         51.941370   \n",
       "2      Damaged beyond repair           NaN               NaN   \n",
       "3      Damaged beyond repair           NaN               NaN   \n",
       "4      Damaged beyond repair           NaN               NaN   \n",
       "...                      ...           ...               ...   \n",
       "22215              Destroyed  Written off          32.821172   \n",
       "22216  Damaged beyond repair           NaN               NaN   \n",
       "22217            Substantial           NaN               NaN   \n",
       "22218  Damaged beyond repair           NaN               NaN   \n",
       "22219                Unknown           NaN               NaN   \n",
       "\n",
       "      accident_longtitude  fatalities  \n",
       "0               10.888056        14.0  \n",
       "1                1.306789         1.0  \n",
       "2                     NaN         0.0  \n",
       "3                     NaN         0.0  \n",
       "4                     NaN         0.0  \n",
       "...                   ...         ...  \n",
       "22215         -116.939520         4.0  \n",
       "22216                 NaN         0.0  \n",
       "22217                 NaN         0.0  \n",
       "22218                 NaN         0.0  \n",
       "22219                 NaN         0.0  \n",
       "\n",
       "[22220 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'weekday':weekday, 'day':day, 'month':month, 'year':year, 'time':time_c, 'aircraft_type':aircraft_type, 'num_of_engines':num_of_engines, 'engine_type':engine_type, 'engine_model':engine_model, 'years_active':years_active, 'airframe_hrs':airframe_hrs, 'cycles':cycles, 'operator':operator, 'occupants':occupants, 'accident_loc':accident_loc, 'above_ocean':above_ocean, 'flight_phase':flight_phase, 'damage':damage, 'fate':fate, 'accident_latitude':accident_latitude, 'accident_longtitude':accident_longtitude, 'fatalities':fatalities})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1787a51b",
   "metadata": {},
   "source": [
    "To proceed to the next step in our project, we will export the dataframe into a .csv file, for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5705c594",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a0cd53",
   "metadata": {},
   "source": [
    "The output file, named <b>\"df.csv\"</b> can be found in our project folder in GitHub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
